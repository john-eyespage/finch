{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 86\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Epoch 1/1 | Batch 0/78896 | train loss: 4.9741\n",
      "\n",
      "le ay*e ay!gle ay*e ayfboj_Spojt ay!!!!!Gt ay!!!!gle aye ay!!!!!!!!!!!!!!!!!!!!!!!!Gt aye aye aye aye aye aye aye ay!!!!Gt aye aye aye aine aye ay*e aye aye aye aye anc<start>le aye aye aye ayfboj_Spoj_Spoj\n",
      "\n",
      "Epoch 1/1 | Batch 10/78896 | train loss: 2.7354\n",
      "Epoch 1/1 | Batch 20/78896 | train loss: 2.5741\n",
      "Epoch 1/1 | Batch 30/78896 | train loss: 2.5138\n",
      "Epoch 1/1 | Batch 40/78896 | train loss: 2.4875\n",
      "Epoch 1/1 | Batch 50/78896 | train loss: 2.4664\n",
      "Epoch 1/1 | Batch 60/78896 | train loss: 2.4542\n",
      "Epoch 1/1 | Batch 70/78896 | train loss: 2.4406\n",
      "Epoch 1/1 | Batch 80/78896 | train loss: 2.4281\n",
      "Epoch 1/1 | Batch 90/78896 | train loss: 2.4156\n",
      "Epoch 1/1 | Batch 100/78896 | train loss: 2.4040\n",
      "\n",
      " he he he he he he he he s he he he he he he he he he he he he he he he he s he he he he he s he he s he he he he he he he he he he he s he he s he s s he he he he he he he s s he he he he he he he he\n",
      "\n",
      "Epoch 1/1 | Batch 110/78896 | train loss: 2.3990\n",
      "Epoch 1/1 | Batch 120/78896 | train loss: 2.3846\n",
      "Epoch 1/1 | Batch 130/78896 | train loss: 2.3705\n",
      "Epoch 1/1 | Batch 140/78896 | train loss: 2.3576\n",
      "Epoch 1/1 | Batch 150/78896 | train loss: 2.3390\n",
      "Epoch 1/1 | Batch 160/78896 | train loss: 2.3249\n",
      "Epoch 1/1 | Batch 170/78896 | train loss: 2.3236\n",
      "Epoch 1/1 | Batch 180/78896 | train loss: 2.3080\n",
      "Epoch 1/1 | Batch 190/78896 | train loss: 2.2931\n",
      "Epoch 1/1 | Batch 200/78896 | train loss: 2.2807\n",
      "\n",
      " he ous t the onon t he he se onouse t t he he he se on se se on t t he he on he ouse he se t he he se on se se on on se on he t on he onon t se t he se ononouse ouse t he he t t t he se on t t he he \n",
      "\n",
      "Epoch 1/1 | Batch 210/78896 | train loss: 2.2710\n",
      "Epoch 1/1 | Batch 220/78896 | train loss: 2.2571\n",
      "Epoch 1/1 | Batch 230/78896 | train loss: 2.2462\n",
      "Epoch 1/1 | Batch 240/78896 | train loss: 2.2365\n",
      "Epoch 1/1 | Batch 250/78896 | train loss: 2.2179\n",
      "Epoch 1/1 | Batch 260/78896 | train loss: 2.2062\n",
      "Epoch 1/1 | Batch 270/78896 | train loss: 2.1905\n",
      "Epoch 1/1 | Batch 280/78896 | train loss: 2.1838\n",
      "Epoch 1/1 | Batch 290/78896 | train loss: 2.1704\n",
      "Epoch 1/1 | Batch 300/78896 | train loss: 2.1585\n",
      "\n",
      " he the the ous t the t onounouse t t the t the the t the the ounoust t t t the the onousoune t t t t the the onounouse t t t the t ousononounononone t t t t t t the the the t the the t the t t the ou\n",
      "\n",
      "Epoch 1/1 | Batch 310/78896 | train loss: 2.1332\n",
      "Epoch 1/1 | Batch 320/78896 | train loss: 2.1345\n",
      "Epoch 1/1 | Batch 330/78896 | train loss: 2.1177\n",
      "Epoch 1/1 | Batch 340/78896 | train loss: 2.1133\n",
      "Epoch 1/1 | Batch 350/78896 | train loss: 2.0923\n",
      "Epoch 1/1 | Batch 360/78896 | train loss: 2.0953\n",
      "Epoch 1/1 | Batch 370/78896 | train loss: 2.0874\n",
      "Epoch 1/1 | Batch 380/78896 | train loss: 2.0632\n",
      "Epoch 1/1 | Batch 390/78896 | train loss: 2.0558\n",
      "Epoch 1/1 | Batch 400/78896 | train loss: 2.0482\n",
      "\n",
      " at the the t the the he was t t t t therererere and at ather at at at at therrond t at the at at at at t athe at the athe at at t arrat the at arind the t the t the on the t the t athe athe on the t \n",
      "\n",
      "Epoch 1/1 | Batch 410/78896 | train loss: 2.0304\n",
      "Epoch 1/1 | Batch 420/78896 | train loss: 2.0229\n",
      "Epoch 1/1 | Batch 430/78896 | train loss: 2.0055\n",
      "Epoch 1/1 | Batch 440/78896 | train loss: 1.9939\n",
      "Epoch 1/1 | Batch 450/78896 | train loss: 1.9815\n",
      "Epoch 1/1 | Batch 460/78896 | train loss: 1.9962\n",
      "Epoch 1/1 | Batch 470/78896 | train loss: 1.9744\n",
      "Epoch 1/1 | Batch 480/78896 | train loss: 1.9754\n",
      "Epoch 1/1 | Batch 490/78896 | train loss: 1.9638\n",
      "Epoch 1/1 | Batch 500/78896 | train loss: 1.9380\n",
      "\n",
      " at the he he st he sthe sthe st stour the cound the t the the sthe the couldre the t the the ar at the ond the\n",
      "me the the that t thathe sthe st lingughe t t t the the the car ond the the car ondr ond\n",
      "\n",
      "Epoch 1/1 | Batch 510/78896 | train loss: 1.9066\n",
      "Epoch 1/1 | Batch 520/78896 | train loss: 1.9287\n",
      "Epoch 1/1 | Batch 530/78896 | train loss: 1.9067\n",
      "Epoch 1/1 | Batch 540/78896 | train loss: 1.8768\n",
      "Epoch 1/1 | Batch 550/78896 | train loss: 1.8655\n",
      "Epoch 1/1 | Batch 560/78896 | train loss: 1.8677\n",
      "Epoch 1/1 | Batch 570/78896 | train loss: 1.8517\n",
      "Epoch 1/1 | Batch 580/78896 | train loss: 1.8242\n",
      "Epoch 1/1 | Batch 590/78896 | train loss: 1.8054\n",
      "Epoch 1/1 | Batch 600/78896 | train loss: 1.8037\n",
      "\n",
      " he could t the the the the could t the the the goughe t t gofffe re the chive wous, as as as as as\n",
      "and te te the te that at te at thate te llle gove gove move more the akit me me\n",
      "the more thin ce the\n",
      "\n",
      "Epoch 1/1 | Batch 610/78896 | train loss: 1.7931\n",
      "Epoch 1/1 | Batch 620/78896 | train loss: 1.7680\n",
      "Epoch 1/1 | Batch 630/78896 | train loss: 1.7536\n",
      "Epoch 1/1 | Batch 640/78896 | train loss: 1.7505\n",
      "Epoch 1/1 | Batch 650/78896 | train loss: 1.7250\n",
      "Epoch 1/1 | Batch 660/78896 | train loss: 1.7090\n",
      "Epoch 1/1 | Batch 670/78896 | train loss: 1.6881\n",
      "Epoch 1/1 | Batch 680/78896 | train loss: 1.6798\n",
      "Epoch 1/1 | Batch 690/78896 | train loss: 1.6600\n",
      "Epoch 1/1 | Batch 700/78896 | train loss: 1.6446\n",
      "\n",
      " he had t to the ther. I the do t do thergo the wave d tho d ther.\n",
      "\n",
      "\n",
      "\"I do do do dowo dowo? do dowowo I do t do t do t t do t that do t nowayo do do t t forgowin.\n",
      "\n",
      "\n",
      "\n",
      "She wowas ay s gond gowawim; buthe\n",
      "\n",
      "Epoch 1/1 | Batch 710/78896 | train loss: 1.6090\n",
      "Epoch 1/1 | Batch 720/78896 | train loss: 1.6100\n",
      "Epoch 1/1 | Batch 730/78896 | train loss: 1.6142\n",
      "Epoch 1/1 | Batch 740/78896 | train loss: 1.5857\n",
      "Epoch 1/1 | Batch 750/78896 | train loss: 1.5744\n",
      "Epoch 1/1 | Batch 760/78896 | train loss: 1.5903\n",
      "Epoch 1/1 | Batch 770/78896 | train loss: 1.5629\n",
      "Epoch 1/1 | Batch 780/78896 | train loss: 1.5416\n",
      "Epoch 1/1 | Batch 790/78896 | train loss: 1.5132\n",
      "Epoch 1/1 | Batch 800/78896 | train loss: 1.5153\n",
      "\n",
      " sher the could t the nould t therse therse w there ssssssssssse tringere ther ther ther the therssssssssss. \"Mining h h conononot the the the could ot onot o othe othersthe of che charte se stoulf\n",
      "ar\n",
      "\n",
      "Epoch 1/1 | Batch 810/78896 | train loss: 1.5120\n",
      "Epoch 1/1 | Batch 820/78896 | train loss: 1.5168\n",
      "Epoch 1/1 | Batch 830/78896 | train loss: 1.4820\n",
      "Epoch 1/1 | Batch 840/78896 | train loss: 1.4822\n",
      "Epoch 1/1 | Batch 850/78896 | train loss: 1.4713\n",
      "Epoch 1/1 | Batch 860/78896 | train loss: 1.4656\n",
      "Epoch 1/1 | Batch 870/78896 | train loss: 1.4377\n",
      "Epoch 1/1 | Batch 880/78896 | train loss: 1.4511\n",
      "Epoch 1/1 | Batch 890/78896 | train loss: 1.4330\n",
      "Epoch 1/1 | Batch 900/78896 | train loss: 1.4100\n",
      "\n",
      " she saligs, cand alind aling his as and owit o o ther saligs th\n",
      "soooooker and her t str the so so wher the cound the w the the s chatoury the w s alamposssion get on of the whin the he the salampllll\n",
      "\n",
      "Epoch 1/1 | Batch 910/78896 | train loss: 1.3967\n",
      "Epoch 1/1 | Batch 920/78896 | train loss: 1.3965\n",
      "Epoch 1/1 | Batch 930/78896 | train loss: 1.3891\n",
      "Epoch 1/1 | Batch 940/78896 | train loss: 1.3804\n",
      "Epoch 1/1 | Batch 950/78896 | train loss: 1.3725\n",
      "Epoch 1/1 | Batch 960/78896 | train loss: 1.3621\n",
      "Epoch 1/1 | Batch 970/78896 | train loss: 1.3455\n",
      "Epoch 1/1 | Batch 980/78896 | train loss: 1.3670\n",
      "Epoch 1/1 | Batch 990/78896 | train loss: 1.3360\n",
      "Epoch 1/1 | Batch 1000/78896 | train loss: 1.3255\n",
      "\n",
      " and the back to o\n",
      "herd w forom. It was so solive he souchis, s and and anld and there\n",
      "wasowe he d dore doway, sou do dowhen dot Matvey ceiroung ong of ther wor per singer ther or ooome\n",
      "one ther begon\n",
      "\n",
      "Epoch 1/1 | Batch 1010/78896 | train loss: 1.3299\n",
      "Epoch 1/1 | Batch 1020/78896 | train loss: 1.3218\n",
      "Epoch 1/1 | Batch 1030/78896 | train loss: 1.2838\n",
      "Epoch 1/1 | Batch 1040/78896 | train loss: 1.3024\n",
      "Epoch 1/1 | Batch 1050/78896 | train loss: 1.3013\n",
      "Epoch 1/1 | Batch 1060/78896 | train loss: 1.2819\n",
      "Epoch 1/1 | Batch 1070/78896 | train loss: 1.2722\n",
      "Epoch 1/1 | Batch 1080/78896 | train loss: 1.2786\n",
      "Epoch 1/1 | Batch 1090/78896 | train loss: 1.2740\n",
      "Epoch 1/1 | Batch 1100/78896 | train loss: 1.2742\n",
      "\n",
      " the was the the the sat do doo t ooo booo to the poans t t Matvey Phimon w? se serid Stepan Arkadyevitch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Arn Hed was hond houlld re id thon tof a the woure therse terese woughe d dim, and the sexpe\n",
      "\n",
      "Epoch 1/1 | Batch 1110/78896 | train loss: 1.2500\n",
      "Epoch 1/1 | Batch 1120/78896 | train loss: 1.2506\n",
      "Epoch 1/1 | Batch 1130/78896 | train loss: 1.2246\n",
      "Epoch 1/1 | Batch 1140/78896 | train loss: 1.2344\n",
      "Epoch 1/1 | Batch 1150/78896 | train loss: 1.2190\n",
      "Epoch 1/1 | Batch 1160/78896 | train loss: 1.2184\n",
      "Epoch 1/1 | Batch 1170/78896 | train loss: 1.2242\n",
      "Epoch 1/1 | Batch 1180/78896 | train loss: 1.2136\n",
      "Epoch 1/1 | Batch 1190/78896 | train loss: 1.1952\n",
      "Epoch 1/1 | Batch 1200/78896 | train loss: 1.1982\n",
      "\n",
      " the sare all aream, and achin ting the scoff his subordeend, the\n",
      "renot whacomed bord oook ow, hend frin his goverienm ht\n",
      "pon with ther com was herersend gof her's comeff cends, and his\n",
      "petts; andind \n",
      "\n",
      "Epoch 1/1 | Batch 1210/78896 | train loss: 1.1813\n",
      "Epoch 1/1 | Batch 1220/78896 | train loss: 1.2128\n",
      "Epoch 1/1 | Batch 1230/78896 | train loss: 1.1957\n",
      "Epoch 1/1 | Batch 1240/78896 | train loss: 1.2005\n",
      "Epoch 1/1 | Batch 1250/78896 | train loss: 1.1813\n",
      "Epoch 1/1 | Batch 1260/78896 | train loss: 1.1813\n",
      "Epoch 1/1 | Batch 1270/78896 | train loss: 1.1685\n",
      "Epoch 1/1 | Batch 1280/78896 | train loss: 1.1823\n",
      "Epoch 1/1 | Batch 1290/78896 | train loss: 1.1817\n",
      "Epoch 1/1 | Batch 1300/78896 | train loss: 1.1463\n",
      "\n",
      " the was frinds the wen al fofone s this which ld come beentof the s lardd cow in this prown hith lath s him. \"Ahereme lere! And Arexact wereming ed fecthing tof the\n",
      "mepart ryereversatersice with ome \n",
      "\n",
      "Epoch 1/1 | Batch 1310/78896 | train loss: 1.1328\n",
      "Epoch 1/1 | Batch 1320/78896 | train loss: 1.1242\n",
      "Epoch 1/1 | Batch 1330/78896 | train loss: 1.1148\n",
      "Epoch 1/1 | Batch 1340/78896 | train loss: 1.1113\n",
      "Epoch 1/1 | Batch 1350/78896 | train loss: 1.1077\n",
      "Epoch 1/1 | Batch 1360/78896 | train loss: 1.0969\n",
      "Epoch 1/1 | Batch 1370/78896 | train loss: 1.1051\n",
      "Epoch 1/1 | Batch 1380/78896 | train loss: 1.0839\n",
      "Epoch 1/1 | Batch 1390/78896 | train loss: 1.0987\n",
      "Epoch 1/1 | Batch 1400/78896 | train loss: 1.0922\n",
      "\n",
      " the begand in therer sposmentintion the pr and of the\n",
      "The eart dje ver of okne of or om ofrownthin histre\n",
      "glonce downsupencenst of omine chary arnduming the of Oblonsky\n",
      "ounsomot, anding his she of ca\n",
      "\n",
      "Epoch 1/1 | Batch 1410/78896 | train loss: 1.0739\n",
      "Epoch 1/1 | Batch 1420/78896 | train loss: 1.0715\n",
      "Epoch 1/1 | Batch 1430/78896 | train loss: 1.0776\n",
      "Epoch 1/1 | Batch 1440/78896 | train loss: 1.0636\n",
      "Epoch 1/1 | Batch 1450/78896 | train loss: 1.0530\n",
      "Epoch 1/1 | Batch 1460/78896 | train loss: 1.0620\n",
      "Epoch 1/1 | Batch 1470/78896 | train loss: 1.0492\n",
      "Epoch 1/1 | Batch 1480/78896 | train loss: 1.0409\n",
      "Epoch 1/1 | Batch 1490/78896 | train loss: 1.0361\n",
      "Epoch 1/1 | Batch 1500/78896 | train loss: 1.0187\n",
      "\n",
      " and the words oo one of the glat of the\n",
      "repos, but for things cant ainthe way as ford and\n",
      "me alof ooke hintw hint; wecant wer anto perd atantay pe ayo the d\n",
      "rourdean ctan turo dever ito ather collati\n",
      "\n",
      "Epoch 1/1 | Batch 1510/78896 | train loss: 1.0118\n",
      "Epoch 1/1 | Batch 1520/78896 | train loss: 1.0021\n",
      "Epoch 1/1 | Batch 1530/78896 | train loss: 1.0239\n",
      "Epoch 1/1 | Batch 1540/78896 | train loss: 1.0210\n",
      "Epoch 1/1 | Batch 1550/78896 | train loss: 1.0033\n",
      "Epoch 1/1 | Batch 1560/78896 | train loss: 0.9996\n",
      "Epoch 1/1 | Batch 1570/78896 | train loss: 1.0140\n",
      "Epoch 1/1 | Batch 1580/78896 | train loss: 1.0111\n",
      "Epoch 1/1 | Batch 1590/78896 | train loss: 1.0061\n",
      "Epoch 1/1 | Batch 1600/78896 | train loss: 0.9951\n",
      "\n",
      " the beear ith mbroy out the the the of the and,\"And isering id, his\n",
      "loong the curet chared had comple tistle, as oong the only ove pethe lad begas every ad in cons counsed ch, gesne witers aly bas on\n",
      "\n",
      "Epoch 1/1 | Batch 1610/78896 | train loss: 0.9950\n",
      "Epoch 1/1 | Batch 1620/78896 | train loss: 0.9723\n",
      "Epoch 1/1 | Batch 1630/78896 | train loss: 0.9866\n",
      "Epoch 1/1 | Batch 1640/78896 | train loss: 0.9673\n",
      "Epoch 1/1 | Batch 1650/78896 | train loss: 0.9636\n",
      "Epoch 1/1 | Batch 1660/78896 | train loss: 0.9621\n",
      "Epoch 1/1 | Batch 1670/78896 | train loss: 0.9554\n",
      "Epoch 1/1 | Batch 1680/78896 | train loss: 0.9800\n",
      "Epoch 1/1 | Batch 1690/78896 | train loss: 0.9504\n",
      "Epoch 1/1 | Batch 1700/78896 | train loss: 0.9585\n",
      "\n",
      " the bat at ilon the rsevely was an lk\n",
      "he hadowas the fathe hir the he hat her was in the cof anthe he re toughir sing the\n",
      "thin the cononsist he sist the ounde to hat hersounde mant heir\n",
      "that psureded\n",
      "\n",
      "Epoch 1/1 | Batch 1710/78896 | train loss: 0.9566\n",
      "Epoch 1/1 | Batch 1720/78896 | train loss: 0.9702\n",
      "Epoch 1/1 | Batch 1730/78896 | train loss: 0.9474\n",
      "Epoch 1/1 | Batch 1740/78896 | train loss: 0.9370\n",
      "Epoch 1/1 | Batch 1750/78896 | train loss: 0.9316\n",
      "Epoch 1/1 | Batch 1760/78896 | train loss: 0.9298\n",
      "Epoch 1/1 | Batch 1770/78896 | train loss: 0.9472\n",
      "Epoch 1/1 | Batch 1780/78896 | train loss: 0.9364\n",
      "Epoch 1/1 | Batch 1790/78896 | train loss: 0.9501\n",
      "Epoch 1/1 | Batch 1800/78896 | train loss: 0.9353\n",
      "\n",
      " to the could not be the in fushe t e hir fachat t e\n",
      "dinestin were the oune tharssssssssse of the thad to the the fr frenchante ouge the\n",
      "was every ir thire was precky the was for the for brom their ca\n",
      "\n",
      "Epoch 1/1 | Batch 1810/78896 | train loss: 0.9381\n",
      "Epoch 1/1 | Batch 1820/78896 | train loss: 0.9355\n",
      "Epoch 1/1 | Batch 1830/78896 | train loss: 0.9393\n",
      "Epoch 1/1 | Batch 1840/78896 | train loss: 0.9422\n",
      "Epoch 1/1 | Batch 1850/78896 | train loss: 0.9488\n",
      "Epoch 1/1 | Batch 1860/78896 | train loss: 0.9475\n",
      "Epoch 1/1 | Batch 1870/78896 | train loss: 0.9445\n",
      "Epoch 1/1 | Batch 1880/78896 | train loss: 0.9375\n",
      "Epoch 1/1 | Batch 1890/78896 | train loss: 0.9280\n",
      "Epoch 1/1 | Batch 1900/78896 | train loss: 0.9231\n",
      "\n",
      " his the count dersiong ther could be nothe the\n",
      "d was for with he his fokver disinng hestimattio t pof this prof hicat was hy\n",
      "was thad in the hathe papresofesor ionst f anthe the cannd eainot the was \n",
      "\n",
      "Epoch 1/1 | Batch 1910/78896 | train loss: 0.9261\n",
      "Epoch 1/1 | Batch 1920/78896 | train loss: 0.9234\n",
      "Epoch 1/1 | Batch 1930/78896 | train loss: 0.9393\n",
      "Epoch 1/1 | Batch 1940/78896 | train loss: 0.9234\n",
      "Epoch 1/1 | Batch 1950/78896 | train loss: 0.8976\n",
      "Epoch 1/1 | Batch 1960/78896 | train loss: 0.9109\n",
      "Epoch 1/1 | Batch 1970/78896 | train loss: 0.9042\n",
      "Epoch 1/1 | Batch 1980/78896 | train loss: 0.8992\n",
      "Epoch 1/1 | Batch 1990/78896 | train loss: 0.8993\n",
      "Epoch 1/1 | Batch 2000/78896 | train loss: 0.9153\n",
      "\n",
      " his the are welve could been nove on with\n",
      "The sold be be isto pen shim thelin cloak suligh at bon cot (herererd therat le san westin o oforman ther\n",
      "the waso herd him thand of theris\n",
      "tingusimened and \n",
      "\n",
      "Epoch 1/1 | Batch 2010/78896 | train loss: 0.9223\n",
      "Epoch 1/1 | Batch 2020/78896 | train loss: 0.9208\n",
      "Epoch 1/1 | Batch 2030/78896 | train loss: 0.8795\n",
      "Epoch 1/1 | Batch 2040/78896 | train loss: 0.8834\n",
      "Epoch 1/1 | Batch 2050/78896 | train loss: 0.8601\n",
      "Epoch 1/1 | Batch 2060/78896 | train loss: 0.8607\n",
      "Epoch 1/1 | Batch 2070/78896 | train loss: 0.8448\n",
      "Epoch 1/1 | Batch 2080/78896 | train loss: 0.8606\n",
      "Epoch 1/1 | Batch 2090/78896 | train loss: 0.8449\n",
      "Epoch 1/1 | Batch 2100/78896 | train loss: 0.8469\n",
      "\n",
      " and pured to seato se.\n",
      "\n",
      "Levin o to was do the wo the melat puresat of the tim,\n",
      "ound had sucorincug onlde athims ont be of suche\n",
      "mes an a ano thexis ereartistationgert o of suboarty, eet andethereey p\n",
      "\n",
      "Epoch 1/1 | Batch 2110/78896 | train loss: 0.8236\n",
      "Epoch 1/1 | Batch 2120/78896 | train loss: 0.8415\n",
      "Epoch 1/1 | Batch 2130/78896 | train loss: 0.8497\n",
      "Epoch 1/1 | Batch 2140/78896 | train loss: 0.8404\n",
      "Epoch 1/1 | Batch 2150/78896 | train loss: 0.8546\n",
      "Epoch 1/1 | Batch 2160/78896 | train loss: 0.8507\n",
      "Epoch 1/1 | Batch 2170/78896 | train loss: 0.8531\n",
      "Epoch 1/1 | Batch 2180/78896 | train loss: 0.8543\n",
      "Epoch 1/1 | Batch 2190/78896 | train loss: 0.8342\n",
      "Epoch 1/1 | Batch 2200/78896 | train loss: 0.8350\n",
      "\n",
      " his the couns ot of at me or sariman,\n",
      "im the and mat and to the conve vereiversition onstalf man, and alend, spered\n",
      "about hat e at thims ther prosoprosof the whassicild wh he\n",
      "cre comptent is of whicl\n",
      "\n",
      "Epoch 1/1 | Batch 2210/78896 | train loss: 0.8144\n",
      "Epoch 1/1 | Batch 2220/78896 | train loss: 0.8000\n",
      "Epoch 1/1 | Batch 2230/78896 | train loss: 0.8133\n",
      "Epoch 1/1 | Batch 2240/78896 | train loss: 0.8382\n",
      "Epoch 1/1 | Batch 2250/78896 | train loss: 0.8274\n",
      "Epoch 1/1 | Batch 2260/78896 | train loss: 0.8322\n",
      "Epoch 1/1 | Batch 2270/78896 | train loss: 0.8120\n",
      "Epoch 1/1 | Batch 2280/78896 | train loss: 0.8263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 2290/78896 | train loss: 0.8220\n",
      "Epoch 1/1 | Batch 2300/78896 | train loss: 0.8096\n",
      "\n",
      " hat he was loner..\"\n",
      "\n",
      "\"What!\" swavitl!\" Levin in der.\"\n",
      "\n",
      "\"Yes, buteghtat his,\" her. he \"I cousand had ppeaco w re su'red?\"\n",
      "\n",
      "\"Ithatere ged Sergey Ivanovitch; \"but he\n",
      "cannot offend me, and I should have \n",
      "\n",
      "Epoch 1/1 | Batch 2310/78896 | train loss: 0.8256\n",
      "Epoch 1/1 | Batch 2320/78896 | train loss: 0.8126\n",
      "Epoch 1/1 | Batch 2330/78896 | train loss: 0.8130\n",
      "Epoch 1/1 | Batch 2340/78896 | train loss: 0.8115\n",
      "Epoch 1/1 | Batch 2350/78896 | train loss: 0.7886\n",
      "Epoch 1/1 | Batch 2360/78896 | train loss: 0.8056\n",
      "Epoch 1/1 | Batch 2370/78896 | train loss: 0.8101\n",
      "Epoch 1/1 | Batch 2380/78896 | train loss: 0.8027\n",
      "Epoch 1/1 | Batch 2390/78896 | train loss: 0.8023\n",
      "Epoch 1/1 | Batch 2400/78896 | train loss: 0.8045\n",
      "\n",
      " of mut that her, appply and the querestion himes ther, and by cauare win that of seer,\n",
      "ance, the were fancese aminty, and sppure acke their\n",
      "twhe frone, alying his hing hir her is stherappacen of the\n",
      "\n",
      "\n",
      "Epoch 1/1 | Batch 2410/78896 | train loss: 0.7993\n",
      "Epoch 1/1 | Batch 2420/78896 | train loss: 0.7837\n",
      "Epoch 1/1 | Batch 2430/78896 | train loss: 0.7736\n",
      "Epoch 1/1 | Batch 2440/78896 | train loss: 0.7939\n",
      "Epoch 1/1 | Batch 2450/78896 | train loss: 0.7941\n",
      "Epoch 1/1 | Batch 2460/78896 | train loss: 0.7844\n",
      "Epoch 1/1 | Batch 2470/78896 | train loss: 0.7868\n",
      "Epoch 1/1 | Batch 2480/78896 | train loss: 0.7889\n",
      "Epoch 1/1 | Batch 2490/78896 | train loss: 0.7770\n",
      "Epoch 1/1 | Batch 2500/78896 | train loss: 0.7640\n",
      "\n",
      " off his\n",
      "welictlif-burarisped ton that skater ithe mitt chome ive the ply cose that him.\n",
      "\n",
      "\"I ano on's a to of had k ince of morthe the im, but on and she see tin fand skate to of seee.\"\n",
      "\"I shor word w\n",
      "\n",
      "Epoch 1/1 | Batch 2510/78896 | train loss: 0.7464\n",
      "Epoch 1/1 | Batch 2520/78896 | train loss: 0.7562\n",
      "Epoch 1/1 | Batch 2530/78896 | train loss: 0.7657\n",
      "Epoch 1/1 | Batch 2540/78896 | train loss: 0.7595\n",
      "Epoch 1/1 | Batch 2550/78896 | train loss: 0.7406\n",
      "Epoch 1/1 | Batch 2560/78896 | train loss: 0.7496\n",
      "Epoch 1/1 | Batch 2570/78896 | train loss: 0.7426\n",
      "Epoch 1/1 | Batch 2580/78896 | train loss: 0.7651\n",
      "Epoch 1/1 | Batch 2590/78896 | train loss: 0.7445\n",
      "Epoch 1/1 | Batch 2600/78896 | train loss: 0.7457\n",
      "\n",
      " he wis smid tha\n",
      "he areros, and with all as so ther or of ererss exce, told ing stesling she skated acred hey arming boung her her eesportacer,\n",
      "and skate he him. She was standing talking to a lady, t \n",
      "\n",
      "Epoch 1/1 | Batch 2610/78896 | train loss: 0.7441\n",
      "Epoch 1/1 | Batch 2620/78896 | train loss: 0.7515\n",
      "Epoch 1/1 | Batch 2630/78896 | train loss: 0.7499\n",
      "Epoch 1/1 | Batch 2640/78896 | train loss: 0.7385\n",
      "Epoch 1/1 | Batch 2650/78896 | train loss: 0.7376\n",
      "Epoch 1/1 | Batch 2660/78896 | train loss: 0.7461\n",
      "Epoch 1/1 | Batch 2670/78896 | train loss: 0.7222\n",
      "Epoch 1/1 | Batch 2680/78896 | train loss: 0.7198\n",
      "Epoch 1/1 | Batch 2690/78896 | train loss: 0.7227\n",
      "Epoch 1/1 | Batch 2700/78896 | train loss: 0.7189\n",
      "\n",
      " here company you,\" he said pleatin the questied mide,\" he anded he cout the was mofice hand thelly saime,\n",
      "m and himseled to the pavile to exprcise,\" hand doten, ancereseed we mil and and efince, and \n",
      "\n",
      "Epoch 1/1 | Batch 2710/78896 | train loss: 0.7104\n",
      "Epoch 1/1 | Batch 2720/78896 | train loss: 0.7180\n",
      "Epoch 1/1 | Batch 2730/78896 | train loss: 0.7218\n",
      "Epoch 1/1 | Batch 2740/78896 | train loss: 0.7396\n",
      "Epoch 1/1 | Batch 2750/78896 | train loss: 0.7241\n",
      "Epoch 1/1 | Batch 2760/78896 | train loss: 0.7322\n",
      "Epoch 1/1 | Batch 2770/78896 | train loss: 0.7280\n",
      "Epoch 1/1 | Batch 2780/78896 | train loss: 0.7374\n",
      "Epoch 1/1 | Batch 2790/78896 | train loss: 0.7099\n",
      "Epoch 1/1 | Batch 2800/78896 | train loss: 0.7157\n",
      "\n",
      " the done the rounded\n",
      "bea theminder to the grother und the the up\n",
      "the mothaidiely best gun gr ofumyshe ehad.\n",
      "\n",
      "\"Hes tousaid and towne the is te gro joke about the three\n",
      "young of ace where spof any and \n",
      "\n",
      "Epoch 1/1 | Batch 2810/78896 | train loss: 0.7087\n",
      "Epoch 1/1 | Batch 2820/78896 | train loss: 0.7496\n",
      "Epoch 1/1 | Batch 2830/78896 | train loss: 0.7064\n",
      "Epoch 1/1 | Batch 2840/78896 | train loss: 0.7325\n",
      "Epoch 1/1 | Batch 2850/78896 | train loss: 0.7038\n",
      "Epoch 1/1 | Batch 2860/78896 | train loss: 0.7022\n",
      "Epoch 1/1 | Batch 2870/78896 | train loss: 0.7101\n",
      "Epoch 1/1 | Batch 2880/78896 | train loss: 0.7193\n",
      "Epoch 1/1 | Batch 2890/78896 | train loss: 0.6942\n",
      "Epoch 1/1 | Batch 2900/78896 | train loss: 0.6929\n",
      "\n",
      " the ben thereing of ther men up to the the ungter an itle\n",
      "of skater, shough opash mered mor-tabled away from his the adkate rnds coming ing her astes.\n",
      "\n",
      "\"Yes, comecalong,\" answered Levin in ecstasy, h\n",
      "\n",
      "Epoch 1/1 | Batch 2910/78896 | train loss: 0.6941\n",
      "Epoch 1/1 | Batch 2920/78896 | train loss: 0.6981\n",
      "Epoch 1/1 | Batch 2930/78896 | train loss: 0.6936\n",
      "Epoch 1/1 | Batch 2940/78896 | train loss: 0.6920\n",
      "Epoch 1/1 | Batch 2950/78896 | train loss: 0.6917\n",
      "Epoch 1/1 | Batch 2960/78896 | train loss: 0.7081\n",
      "Epoch 1/1 | Batch 2970/78896 | train loss: 0.6878\n",
      "Epoch 1/1 | Batch 2980/78896 | train loss: 0.7037\n",
      "Epoch 1/1 | Batch 2990/78896 | train loss: 0.6833\n",
      "Epoch 1/1 | Batch 3000/78896 | train loss: 0.6986\n",
      "\n",
      " the bear the nad comptled then the\n",
      "whemad in the he could the the offor he ck on the hir.\"\n",
      "\n",
      "Thelik inking ing his king of tod, he sathe the woughe fis heart ing his\n",
      "ofand st conessiting his\n",
      "pat, and \n",
      "\n",
      "Epoch 1/1 | Batch 3010/78896 | train loss: 0.7022\n",
      "Epoch 1/1 | Batch 3020/78896 | train loss: 0.6750\n",
      "Epoch 1/1 | Batch 3030/78896 | train loss: 0.6577\n",
      "Epoch 1/1 | Batch 3040/78896 | train loss: 0.6696\n",
      "Epoch 1/1 | Batch 3050/78896 | train loss: 0.6454\n",
      "Epoch 1/1 | Batch 3060/78896 | train loss: 0.6389\n",
      "Epoch 1/1 | Batch 3070/78896 | train loss: 0.6345\n",
      "Epoch 1/1 | Batch 3080/78896 | train loss: 0.6480\n",
      "Epoch 1/1 | Batch 3090/78896 | train loss: 0.6256\n",
      "Epoch 1/1 | Batch 3100/78896 | train loss: 0.6376\n",
      "\n",
      " the dining room, giving directions to the Tatar waiters, who were\n",
      "clustered about him in evening coats, bearing napkins. Bowing to right\n",
      "and left to the people he met, and here as everywhere joyously\n",
      "\n",
      "Epoch 1/1 | Batch 3110/78896 | train loss: 0.6301\n",
      "Epoch 1/1 | Batch 3120/78896 | train loss: 0.6466\n",
      "Epoch 1/1 | Batch 3130/78896 | train loss: 0.6152\n",
      "Epoch 1/1 | Batch 3140/78896 | train loss: 0.6288\n",
      "Epoch 1/1 | Batch 3150/78896 | train loss: 0.6350\n",
      "Epoch 1/1 | Batch 3160/78896 | train loss: 0.6419\n",
      "Epoch 1/1 | Batch 3170/78896 | train loss: 0.6203\n",
      "Epoch 1/1 | Batch 3180/78896 | train loss: 0.6247\n",
      "Epoch 1/1 | Batch 3190/78896 | train loss: 0.6305\n",
      "Epoch 1/1 | Batch 3200/78896 | train loss: 0.6289\n",
      "\n",
      " and thought\n",
      "wents of to diver ch als, excellency won you\n",
      "orkis ef win a with a dinn vier anoth.\"\n",
      "\n",
      "\"Yes, like sik a wea suere with a sand mor.\"\n",
      "\n",
      "\"Beaces. \"Well be,\" all she said Levin, and hing dere a\n",
      "\n",
      "Epoch 1/1 | Batch 3210/78896 | train loss: 0.6180\n",
      "Epoch 1/1 | Batch 3220/78896 | train loss: 0.6219\n",
      "Epoch 1/1 | Batch 3230/78896 | train loss: 0.6327\n",
      "Epoch 1/1 | Batch 3240/78896 | train loss: 0.6137\n",
      "Epoch 1/1 | Batch 3250/78896 | train loss: 0.6148\n",
      "Epoch 1/1 | Batch 3260/78896 | train loss: 0.6354\n",
      "Epoch 1/1 | Batch 3270/78896 | train loss: 0.6426\n",
      "Epoch 1/1 | Batch 3280/78896 | train loss: 0.6357\n",
      "Epoch 1/1 | Batch 3290/78896 | train loss: 0.6098\n",
      "Epoch 1/1 | Batch 3300/78896 | train loss: 0.6179\n",
      "\n",
      " and so more so why as\n",
      "ouread purely the way a frene from\n",
      "the tooorthere, we's, and the dit's\n",
      "happready him.\"\n",
      "\n",
      "\"Wholl, asaid hat?\" said Stepan Arkadyevitch, smiling at his\n",
      "excitement.\n",
      "\n",
      "\"It seems so to\n",
      "\n",
      "Epoch 1/1 | Batch 3310/78896 | train loss: 0.6233\n",
      "Epoch 1/1 | Batch 3320/78896 | train loss: 0.6234\n",
      "Epoch 1/1 | Batch 3330/78896 | train loss: 0.6177\n",
      "Epoch 1/1 | Batch 3340/78896 | train loss: 0.6069\n",
      "Epoch 1/1 | Batch 3350/78896 | train loss: 0.6109\n",
      "Epoch 1/1 | Batch 3360/78896 | train loss: 0.6113\n",
      "Epoch 1/1 | Batch 3370/78896 | train loss: 0.6322\n",
      "Epoch 1/1 | Batch 3380/78896 | train loss: 0.6117\n",
      "Epoch 1/1 | Batch 3390/78896 | train loss: 0.6220\n",
      "Epoch 1/1 | Batch 3400/78896 | train loss: 0.6252\n",
      "\n",
      " and whate ture the wo a din was ther, can for ases was se or to mornot\n",
      "thandse alk. His work is with the mind...\"\n",
      "\n",
      "\"Maybe. But still it's queer to me, just as at this moment it seems\n",
      "queer to me that\n",
      "\n",
      "Epoch 1/1 | Batch 3410/78896 | train loss: 0.6142\n",
      "Epoch 1/1 | Batch 3420/78896 | train loss: 0.5975\n",
      "Epoch 1/1 | Batch 3430/78896 | train loss: 0.6113\n",
      "Epoch 1/1 | Batch 3440/78896 | train loss: 0.6044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 3450/78896 | train loss: 0.5971\n",
      "Epoch 1/1 | Batch 3460/78896 | train loss: 0.5903\n",
      "Epoch 1/1 | Batch 3470/78896 | train loss: 0.5844\n",
      "Epoch 1/1 | Batch 3480/78896 | train loss: 0.5957\n",
      "Epoch 1/1 | Batch 3490/78896 | train loss: 0.6101\n",
      "Epoch 1/1 | Batch 3500/78896 | train loss: 0.5831\n",
      "\n",
      " one, giveng and hisen bec restrall the classell toone of ther, whilerent's one offf rom tears of emotion.\n",
      "\n",
      "\"She says that!\" cried Levin. \"I always said she was exquisite, your\n",
      "wife. There, that's eno\n",
      "\n",
      "Epoch 1/1 | Batch 3510/78896 | train loss: 0.5884\n",
      "Epoch 1/1 | Batch 3520/78896 | train loss: 0.5915\n",
      "Epoch 1/1 | Batch 3530/78896 | train loss: 0.5901\n",
      "Epoch 1/1 | Batch 3540/78896 | train loss: 0.5806\n",
      "Epoch 1/1 | Batch 3550/78896 | train loss: 0.5839\n",
      "Epoch 1/1 | Batch 3560/78896 | train loss: 0.6037\n",
      "Epoch 1/1 | Batch 3570/78896 | train loss: 0.6034\n",
      "Epoch 1/1 | Batch 3580/78896 | train loss: 0.6015\n",
      "Epoch 1/1 | Batch 3590/78896 | train loss: 0.5807\n",
      "Epoch 1/1 | Batch 3600/78896 | train loss: 0.5943\n",
      "\n",
      " married, you know there done, for thim the therew. I have never spoking berett, and back fes the feeling and blicalliged an tur tleas mily rece.\"\n",
      "\n",
      "\"One word more: in any case I advise you to settle t\n",
      "\n",
      "Epoch 1/1 | Batch 3610/78896 | train loss: 0.5999\n",
      "Epoch 1/1 | Batch 3620/78896 | train loss: 0.5841\n",
      "Epoch 1/1 | Batch 3630/78896 | train loss: 0.5862\n",
      "Epoch 1/1 | Batch 3640/78896 | train loss: 0.6001\n",
      "Epoch 1/1 | Batch 3650/78896 | train loss: 0.5895\n",
      "Epoch 1/1 | Batch 3660/78896 | train loss: 0.5979\n",
      "Epoch 1/1 | Batch 3670/78896 | train loss: 0.5952\n",
      "Epoch 1/1 | Batch 3680/78896 | train loss: 0.5957\n",
      "Epoch 1/1 | Batch 3690/78896 | train loss: 0.6191\n",
      "Epoch 1/1 | Batch 3700/78896 | train loss: 0.6080\n",
      "\n",
      " marriantch way was the hing to near. All wit frords ing and the was ther, very whaver, and are gifrought fing siled she for thand mor the cardeld\n",
      "goo, you know that had le any bamaker\n",
      "Now, fely Pevev\n",
      "\n",
      "Epoch 1/1 | Batch 3710/78896 | train loss: 0.6070\n",
      "Epoch 1/1 | Batch 3720/78896 | train loss: 0.6063\n",
      "Epoch 1/1 | Batch 3730/78896 | train loss: 0.6026\n",
      "Epoch 1/1 | Batch 3740/78896 | train loss: 0.5875\n",
      "Epoch 1/1 | Batch 3750/78896 | train loss: 0.6011\n",
      "Epoch 1/1 | Batch 3760/78896 | train loss: 0.6172\n",
      "Epoch 1/1 | Batch 3770/78896 | train loss: 0.6166\n",
      "Epoch 1/1 | Batch 3780/78896 | train loss: 0.6024\n",
      "Epoch 1/1 | Batch 3790/78896 | train loss: 0.6070\n",
      "Epoch 1/1 | Batch 3800/78896 | train loss: 0.6133\n",
      "\n",
      " of lif lifface\n",
      "the yor int woment a\n",
      "ster reaure to as as of of and on this mats, an hat's to bey of do do not ther one criss faughters with ons very\n",
      "unt Kitty. The princess and he from por the sirs t\n",
      "\n",
      "Epoch 1/1 | Batch 3810/78896 | train loss: 0.5937\n",
      "Epoch 1/1 | Batch 3820/78896 | train loss: 0.6052\n",
      "Epoch 1/1 | Batch 3830/78896 | train loss: 0.5806\n",
      "Epoch 1/1 | Batch 3840/78896 | train loss: 0.6007\n",
      "Epoch 1/1 | Batch 3850/78896 | train loss: 0.5905\n",
      "Epoch 1/1 | Batch 3860/78896 | train loss: 0.5871\n",
      "Epoch 1/1 | Batch 3870/78896 | train loss: 0.5878\n",
      "Epoch 1/1 | Batch 3880/78896 | train loss: 0.5904\n",
      "Epoch 1/1 | Batch 3890/78896 | train loss: 0.5884\n",
      "Epoch 1/1 | Batch 3900/78896 | train loss: 0.5917\n",
      "\n",
      " ther mothe great an that young, that Levin had\n",
      "done nothing to prove that he had serious intentions, that Kitty felt no\n",
      "great to beling alled the no sto maks of some same.\"\n",
      "\n",
      "In some the whe do the no\n",
      "\n",
      "Epoch 1/1 | Batch 3910/78896 | train loss: 0.5852\n",
      "Epoch 1/1 | Batch 3920/78896 | train loss: 0.5752\n",
      "Epoch 1/1 | Batch 3930/78896 | train loss: 0.5853\n",
      "Epoch 1/1 | Batch 3940/78896 | train loss: 0.5764\n",
      "Epoch 1/1 | Batch 3950/78896 | train loss: 0.5779\n",
      "Epoch 1/1 | Batch 3960/78896 | train loss: 0.5817\n",
      "Epoch 1/1 | Batch 3970/78896 | train loss: 0.5709\n",
      "Epoch 1/1 | Batch 3980/78896 | train loss: 0.5673\n",
      "Epoch 1/1 | Batch 3990/78896 | train loss: 0.5691\n",
      "Epoch 1/1 | Batch 4000/78896 | train loss: 0.5633\n",
      "\n",
      " st he with Vronsky during a mazurka.\n",
      "This conversation her purtly thing he to marry the se aronge ther girls with ther evendels, buthe hought fe were the dis with her on elderst\n",
      "ungs, whought be mad \n",
      "\n",
      "Epoch 1/1 | Batch 4010/78896 | train loss: 0.5722\n",
      "Epoch 1/1 | Batch 4020/78896 | train loss: 0.5824\n",
      "Epoch 1/1 | Batch 4030/78896 | train loss: 0.5820\n",
      "Epoch 1/1 | Batch 4040/78896 | train loss: 0.5729\n",
      "Epoch 1/1 | Batch 4050/78896 | train loss: 0.5724\n",
      "Epoch 1/1 | Batch 4060/78896 | train loss: 0.5752\n",
      "Epoch 1/1 | Batch 4070/78896 | train loss: 0.5743\n",
      "Epoch 1/1 | Batch 4080/78896 | train loss: 0.5666\n",
      "Epoch 1/1 | Batch 4090/78896 | train loss: 0.5564\n",
      "Epoch 1/1 | Batch 4100/78896 | train loss: 0.5571\n",
      "\n",
      " as mome shing ther spearand stat was tairs old f they nes, usher of her daughtly serious of all the. She looked me, looked hat she was ing ithing, in ar she felight.\"\n",
      "When in the the what lover had n\n",
      "\n",
      "Epoch 1/1 | Batch 4110/78896 | train loss: 0.5485\n",
      "Epoch 1/1 | Batch 4120/78896 | train loss: 0.5381\n",
      "Epoch 1/1 | Batch 4130/78896 | train loss: 0.5465\n",
      "Epoch 1/1 | Batch 4140/78896 | train loss: 0.5489\n",
      "Epoch 1/1 | Batch 4150/78896 | train loss: 0.5393\n",
      "Epoch 1/1 | Batch 4160/78896 | train loss: 0.5508\n",
      "Epoch 1/1 | Batch 4170/78896 | train loss: 0.5572\n",
      "Epoch 1/1 | Batch 4180/78896 | train loss: 0.5541\n",
      "Epoch 1/1 | Batch 4190/78896 | train loss: 0.5538\n",
      "Epoch 1/1 | Batch 4200/78896 | train loss: 0.5373\n",
      "\n",
      " as the was uppited with makeas sorto ifious for Levin all\n",
      "reat.\n",
      "\n",
      "Her she mot for gess. Her ought happectly offect on her daught so ldest daughter, was in the moment was a feexpectanted whould\n",
      "she mon\n",
      "\n",
      "Epoch 1/1 | Batch 4210/78896 | train loss: 0.5604\n",
      "Epoch 1/1 | Batch 4220/78896 | train loss: 0.5635\n",
      "Epoch 1/1 | Batch 4230/78896 | train loss: 0.5819\n",
      "Epoch 1/1 | Batch 4240/78896 | train loss: 0.5671\n",
      "Epoch 1/1 | Batch 4250/78896 | train loss: 0.5565\n",
      "Epoch 1/1 | Batch 4260/78896 | train loss: 0.5627\n",
      "Epoch 1/1 | Batch 4270/78896 | train loss: 0.5635\n",
      "Epoch 1/1 | Batch 4280/78896 | train loss: 0.5461\n",
      "Epoch 1/1 | Batch 4290/78896 | train loss: 0.5425\n",
      "Epoch 1/1 | Batch 4300/78896 | train loss: 0.5402\n",
      "\n",
      " as they was realized that to believe wout be men makseally,\n",
      "thing remake want thosing glay, and a not a the and speace.\n",
      "\n",
      "So bat her reasky ing er lone of Levin's friendship with her dead brother gave\n",
      "\n",
      "Epoch 1/1 | Batch 4310/78896 | train loss: 0.5318\n",
      "Epoch 1/1 | Batch 4320/78896 | train loss: 0.5185\n",
      "Epoch 1/1 | Batch 4330/78896 | train loss: 0.5289\n",
      "Epoch 1/1 | Batch 4340/78896 | train loss: 0.5408\n",
      "Epoch 1/1 | Batch 4350/78896 | train loss: 0.5570\n",
      "Epoch 1/1 | Batch 4360/78896 | train loss: 0.5342\n",
      "Epoch 1/1 | Batch 4370/78896 | train loss: 0.5381\n",
      "Epoch 1/1 | Batch 4380/78896 | train loss: 0.5226\n",
      "Epoch 1/1 | Batch 4390/78896 | train loss: 0.5309\n",
      "Epoch 1/1 | Batch 4400/78896 | train loss: 0.5091\n",
      "\n",
      " with a fewas and of her match for Kitty after her own ideal of married happiness; she\n",
      "wanted her to marry Vronsky. Levin she had often met at the\n",
      "Shtcherbatskys' early in the winter, and she had alwa\n",
      "\n",
      "Epoch 1/1 | Batch 4410/78896 | train loss: 0.5182\n",
      "Epoch 1/1 | Batch 4420/78896 | train loss: 0.5052\n",
      "Epoch 1/1 | Batch 4430/78896 | train loss: 0.5354\n",
      "Epoch 1/1 | Batch 4440/78896 | train loss: 0.5155\n",
      "Epoch 1/1 | Batch 4450/78896 | train loss: 0.5142\n",
      "Epoch 1/1 | Batch 4460/78896 | train loss: 0.5203\n",
      "Epoch 1/1 | Batch 4470/78896 | train loss: 0.5147\n",
      "Epoch 1/1 | Batch 4480/78896 | train loss: 0.5126\n",
      "Epoch 1/1 | Batch 4490/78896 | train loss: 0.5273\n",
      "Epoch 1/1 | Batch 4500/78896 | train loss: 0.5089\n",
      "\n",
      " the look of her eyes, that grat her meare some a stion off er.\n",
      "\n",
      "Nordseratimpespedull of what in rery, thould the consy of the rell, that-that ct's that the samile words the looky, was a ppince, what'\n",
      "\n",
      "Epoch 1/1 | Batch 4510/78896 | train loss: 0.5105\n",
      "Epoch 1/1 | Batch 4520/78896 | train loss: 0.5112\n",
      "Epoch 1/1 | Batch 4530/78896 | train loss: 0.5107\n",
      "Epoch 1/1 | Batch 4540/78896 | train loss: 0.5166\n",
      "Epoch 1/1 | Batch 4550/78896 | train loss: 0.5099\n",
      "Epoch 1/1 | Batch 4560/78896 | train loss: 0.5121\n",
      "Epoch 1/1 | Batch 4570/78896 | train loss: 0.5333\n",
      "Epoch 1/1 | Batch 4580/78896 | train loss: 0.5152\n",
      "Epoch 1/1 | Batch 4590/78896 | train loss: 0.5245\n",
      "Epoch 1/1 | Batch 4600/78896 | train loss: 0.5116\n",
      "\n",
      " the look now was regand a not\n",
      "sople eman, and aot asame of his only make who who re the conscee us..\n",
      "\n",
      "\"Why do you ask me? Younk I to to low?\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Dme dome will be pen the belied lovers. I amave was dre\n",
      "\n",
      "Epoch 1/1 | Batch 4610/78896 | train loss: 0.5163\n",
      "Epoch 1/1 | Batch 4620/78896 | train loss: 0.5154\n",
      "Epoch 1/1 | Batch 4630/78896 | train loss: 0.5163\n",
      "Epoch 1/1 | Batch 4640/78896 | train loss: 0.5063\n",
      "Epoch 1/1 | Batch 4650/78896 | train loss: 0.5234\n",
      "Epoch 1/1 | Batch 4660/78896 | train loss: 0.5138\n",
      "Epoch 1/1 | Batch 4670/78896 | train loss: 0.5011\n",
      "Epoch 1/1 | Batch 4680/78896 | train loss: 0.4966\n",
      "Epoch 1/1 | Batch 4690/78896 | train loss: 0.4884\n",
      "Epoch 1/1 | Batch 4700/78896 | train loss: 0.4914\n",
      "\n",
      " the country, Russian\n",
      "country, with bast shoes and peasants, as when I was spending a winter\n",
      "with my mother in Nice. Nice itself is dull enough, you know. And\n",
      "indeed, Naples and Sorrento are only plea\n",
      "\n",
      "Epoch 1/1 | Batch 4710/78896 | train loss: 0.4980\n",
      "Epoch 1/1 | Batch 4720/78896 | train loss: 0.4946\n",
      "Epoch 1/1 | Batch 4730/78896 | train loss: 0.5024\n",
      "Epoch 1/1 | Batch 4740/78896 | train loss: 0.5136\n",
      "Epoch 1/1 | Batch 4750/78896 | train loss: 0.5149\n",
      "Epoch 1/1 | Batch 4760/78896 | train loss: 0.5044\n",
      "Epoch 1/1 | Batch 4770/78896 | train loss: 0.4918\n",
      "Epoch 1/1 | Batch 4780/78896 | train loss: 0.4956\n",
      "Epoch 1/1 | Batch 4790/78896 | train loss: 0.5076\n",
      "Epoch 1/1 | Batch 4800/78896 | train loss: 0.5188\n",
      "\n",
      " she wither..\n",
      "\n",
      "\"It's not durn ing you,\" said Levin, why and, becand to a in of thim so imat baccusisiouits mal No, and Countounter, Counte Nordston iturncess Nordston of\n",
      "the greate incerelible-to a ma\n",
      "\n",
      "Epoch 1/1 | Batch 4810/78896 | train loss: 0.5173\n",
      "Epoch 1/1 | Batch 4820/78896 | train loss: 0.5179\n",
      "Epoch 1/1 | Batch 4830/78896 | train loss: 0.5208\n",
      "Epoch 1/1 | Batch 4840/78896 | train loss: 0.5075\n",
      "Epoch 1/1 | Batch 4850/78896 | train loss: 0.4929\n",
      "Epoch 1/1 | Batch 4860/78896 | train loss: 0.5095\n",
      "Epoch 1/1 | Batch 4870/78896 | train loss: 0.5078\n",
      "Epoch 1/1 | Batch 4880/78896 | train loss: 0.5019\n",
      "Epoch 1/1 | Batch 4890/78896 | train loss: 0.4846\n",
      "Epoch 1/1 | Batch 4900/78896 | train loss: 0.5028\n",
      "\n",
      " had listened nothim.\n",
      "\n",
      "Kitty felt how distasteful her father's warmth was to Levin after what\n",
      "had happened. She saw, too, how coldly her father responded at last to\n",
      "Vronsky's bow, and how Vronsky look\n",
      "\n",
      "Epoch 1/1 | Batch 4910/78896 | train loss: 0.5027\n",
      "Epoch 1/1 | Batch 4920/78896 | train loss: 0.5119\n",
      "Epoch 1/1 | Batch 4930/78896 | train loss: 0.4849\n",
      "Epoch 1/1 | Batch 4940/78896 | train loss: 0.5024\n",
      "Epoch 1/1 | Batch 4950/78896 | train loss: 0.5067\n",
      "Epoch 1/1 | Batch 4960/78896 | train loss: 0.4883\n",
      "Epoch 1/1 | Batch 4970/78896 | train loss: 0.4859\n",
      "Epoch 1/1 | Batch 4980/78896 | train loss: 0.5052\n",
      "Epoch 1/1 | Batch 4990/78896 | train loss: 0.5042\n",
      "Epoch 1/1 | Batch 5000/78896 | train loss: 0.4995\n",
      "\n",
      " her pally worand the had coused him. He cardat Al thad the had been Count ess Nordston had not beraw havords he paring wered with he face, was he pas fare parting they eal the\n",
      "was miman for him. It t\n",
      "\n",
      "Epoch 1/1 | Batch 5010/78896 | train loss: 0.4974\n",
      "Epoch 1/1 | Batch 5020/78896 | train loss: 0.5224\n",
      "Epoch 1/1 | Batch 5030/78896 | train loss: 0.5335\n",
      "Epoch 1/1 | Batch 5040/78896 | train loss: 0.5205\n",
      "Epoch 1/1 | Batch 5050/78896 | train loss: 0.5213\n",
      "Epoch 1/1 | Batch 5060/78896 | train loss: 0.5189\n",
      "Epoch 1/1 | Batch 5070/78896 | train loss: 0.5031\n",
      "Epoch 1/1 | Batch 5080/78896 | train loss: 0.5132\n",
      "Epoch 1/1 | Batch 5090/78896 | train loss: 0.5070\n",
      "Epoch 1/1 | Batch 5100/78896 | train loss: 0.5089\n",
      "\n",
      " her even princess with\n",
      "faich the cally ling, and oubt, as the knowith s for happirity Levin could, him, and have only\n",
      "cat the with him able- parthe a nothing.\n",
      "\n",
      "\"Arist to use, all to came suck in. \"Bu\n",
      "\n",
      "Epoch 1/1 | Batch 5110/78896 | train loss: 0.5212\n"
     ]
    }
   ],
   "source": [
    "from self_attn_lm import LM\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with open('./temp/anna.txt') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    model = LM(text, seq_len=200)\n",
    "    log = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
