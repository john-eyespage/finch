{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shuffled\n",
      "Epoch 1/1 | Step 0/1142 | train_loss: 72.9835 | train_acc: 0.2825 | lr: 0.0050\n",
      "Epoch 1/1 | Step 50/1142 | train_loss: 16.9622 | train_acc: 0.8645 | lr: 0.0045\n",
      "Epoch 1/1 | Step 100/1142 | train_loss: 11.6213 | train_acc: 0.9047 | lr: 0.0041\n",
      "Epoch 1/1 | Step 150/1142 | train_loss: 9.0541 | train_acc: 0.9217 | lr: 0.0037\n",
      "Epoch 1/1 | Step 200/1142 | train_loss: 7.9366 | train_acc: 0.9322 | lr: 0.0033\n",
      "Epoch 1/1 | Step 250/1142 | train_loss: 6.7939 | train_acc: 0.9378 | lr: 0.0030\n",
      "Epoch 1/1 | Step 300/1142 | train_loss: 6.3876 | train_acc: 0.9427 | lr: 0.0027\n",
      "Epoch 1/1 | Step 350/1142 | train_loss: 4.4476 | train_acc: 0.9573 | lr: 0.0025\n",
      "Epoch 1/1 | Step 400/1142 | train_loss: 4.9978 | train_acc: 0.9545 | lr: 0.0022\n",
      "Epoch 1/1 | Step 450/1142 | train_loss: 4.7030 | train_acc: 0.9516 | lr: 0.0020\n",
      "Epoch 1/1 | Step 500/1142 | train_loss: 4.7219 | train_acc: 0.9533 | lr: 0.0018\n",
      "Epoch 1/1 | Step 550/1142 | train_loss: 3.7299 | train_acc: 0.9641 | lr: 0.0016\n",
      "Epoch 1/1 | Step 600/1142 | train_loss: 4.1033 | train_acc: 0.9586 | lr: 0.0015\n",
      "Epoch 1/1 | Step 650/1142 | train_loss: 3.8919 | train_acc: 0.9631 | lr: 0.0013\n",
      "Epoch 1/1 | Step 700/1142 | train_loss: 3.8671 | train_acc: 0.9609 | lr: 0.0012\n",
      "Epoch 1/1 | Step 750/1142 | train_loss: 3.0843 | train_acc: 0.9709 | lr: 0.0011\n",
      "Epoch 1/1 | Step 800/1142 | train_loss: 3.1148 | train_acc: 0.9708 | lr: 0.0010\n",
      "Epoch 1/1 | Step 850/1142 | train_loss: 3.5323 | train_acc: 0.9642 | lr: 0.0009\n",
      "Epoch 1/1 | Step 900/1142 | train_loss: 2.6492 | train_acc: 0.9753 | lr: 0.0008\n",
      "Epoch 1/1 | Step 950/1142 | train_loss: 2.5880 | train_acc: 0.9741 | lr: 0.0007\n",
      "Epoch 1/1 | Step 1000/1142 | train_loss: 2.7488 | train_acc: 0.9728 | lr: 0.0007\n",
      "Epoch 1/1 | Step 1050/1142 | train_loss: 3.3063 | train_acc: 0.9669 | lr: 0.0006\n",
      "Epoch 1/1 | Step 1100/1142 | train_loss: 3.1705 | train_acc: 0.9695 | lr: 0.0005\n",
      "Epoch 1/1 | train_loss: 3.0633 | train_acc: 0.9723 | lr: 0.0005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.94      0.95      0.95    116058\n",
      "          M       0.86      0.80      0.83     25425\n",
      "          E       0.94      0.95      0.95    116057\n",
      "          S       0.94      0.93      0.93    106810\n",
      "\n",
      "avg / total       0.93      0.94      0.93    364350\n",
      "\n",
      "我 来到 大学 读书 ， 希望 学 到 知识\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import chseg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from birnn_crf_clf import BiRNN_CRF\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "SEQ_LEN = 50\n",
    "N_CLASS = 4 # B: 0, M: 1, E: 2, S: 3\n",
    "N_EPOCH = 1\n",
    "BATCH_SIZE = 128\n",
    "sample = '我来到大学读书，希望学到知识'\n",
    "py = int(sys.version[0])\n",
    "\n",
    "\n",
    "def to_train_seq(*args):\n",
    "    data = []\n",
    "    for x in args:\n",
    "        data.append(iter_seq(x))\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_test_seq(*args):\n",
    "    data = []\n",
    "    for x in args:\n",
    "        x = x[: (len(x) - len(x) % SEQ_LEN)]\n",
    "        data.append(np.reshape(x, [-1, SEQ_LEN]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def iter_seq(x, text_iter_step=10):\n",
    "    return np.array([x[i : i+SEQ_LEN] for i in range(0, len(x)-SEQ_LEN, text_iter_step)])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x_train, y_train, x_test, y_test, vocab_size, char2idx, idx2char = chseg.load_data()\n",
    "    X_train, Y_train = to_train_seq(x_train, y_train)\n",
    "    X_test, Y_test = to_test_seq(x_test, y_test)\n",
    "    print('Vocab size: %d' % vocab_size)\n",
    "\n",
    "    clf = BiRNN_CRF(vocab_size, N_CLASS)\n",
    "    clf.fit(X_train, Y_train, n_epoch=N_EPOCH, batch_size=BATCH_SIZE)\n",
    "\n",
    "    y_pred = clf.predict(X_test, batch_size=BATCH_SIZE)\n",
    "    print(classification_report(Y_test.ravel(), y_pred.ravel(), target_names=['B', 'M', 'E', 'S']))\n",
    "    \n",
    "    chars = list(sample) if py == 3 else list(sample.decode('utf-8'))\n",
    "    labels = clf.infer([char2idx[c] for c in chars])\n",
    "    res = ''\n",
    "    for i, l in enumerate(labels):\n",
    "        c = sample[i] if py == 3 else sample.decode('utf-8')[i]\n",
    "        if l == 2 or l == 3:\n",
    "            c += ' '\n",
    "        res += c\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
